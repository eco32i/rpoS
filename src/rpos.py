from __future__ import division

import pandas as pd
import numpy as np
import pysam
import csv
import re
import os

# RE to match the gene field: thrC(3734,5020)
gene_re = re.compile('^(?P<gene_name>\S+)\((?P<gene_5>\d+),(?P<gene_3>\d+)\)')

def bed_from_df(df, filename, fields, field_overrides=None):
    '''
    Outputs .bed file from dataframe using specified fields.
    '''
    with open(filename, 'w') as fo:
        #writer = csv.DictWriter(fo, fieldnames=fields, delimiter='\t')
        lines = []
        for ind,row in df.iterrows():
            csv_row = dict()
            for field in fields:
                try:
                    csv_row.update({field: row[field]})
                except KeyError:
                    pass
            if field_overrides:
                csv_row.update(field_overrides)
            start, end = row[fields[1]], row[fields[2]]
            if start > end:
                csv_row.update({fields[1]: end, fields[2]: start,})
            lines.append('\t'.join([str(csv_row[f]) for f in fields]))
        fo.write('\n'.join(lines))

def get_utr5_df(filename):
    '''
    Parses the annotation file for 5' UTRs and returns DataFrame  with the following
    columns:
        - operon
        - TU_name
        - promoter
        - TSS
        - 5' UTR coord
        - 3' UTR coord
        - first gene 5' coord
        - first gene 3' coord
    '''
    fieldnames = [
            'operon',
            'TU_name',
            'promoter',
            'TSS',
            'strand',
            'first_gene',
            'last_gene',
            'term_type',
            'coord_UTR',
            'coord_5UTR',
            'seq_5UTR',
            'coord_3UTR',
            'seq_3UTR'
            ]
    UTR5_list = []
    with open(filename) as fi:
        reader = csv.DictReader(fi, fieldnames=fieldnames, delimiter='\t')
        for rec in reader:
            if not rec['operon'].startswith('#'):
                if rec['coord_5UTR']:
                    c5,c3 = rec['coord_5UTR'].split('-')
                    gene_match = gene_re.search(rec['first_gene'])
                    UTR5_list.append(dict(
                        operon=rec['operon'],
                        TU_name=rec['TU_name'],
                        promoter=rec['promoter'],
                        TSS=rec['TSS'],
                        coord_5=int(c5),
                        coord_3=int(c3),
                        first_gene_name=gene_match.group('gene_name'),
                        first_gene_3=int(gene_match.group('gene_3')),
                        first_gene_5=int(gene_match.group('gene_5')),
                        seq_5UTR=rec['seq_5UTR']))
        return pd.DataFrame.from_records(UTR5_list)


def get_predictions(filename):
    '''
    Parses the .csv file generated by RNAPredator (http://rna.tbi.univie.ac.at/RNApredator2/target_search.cgi)
    and returns a DataFrame with the following columns:
        - rank
        - coord_5
        - coord_3
        - energy
        - z_score
        - locus
    '''
    with open(filename) as fi:
        fieldnames = ['rank', 'acc1', 'acc2', 'coord', 'interaction', 'mrna_start', 'mrna_end', 'srna_start','srna_end', 'energy', 'x', 'xx','xxx','z_score','annot','locus','replicon','uid']
        targets = []
        reader = csv.DictReader(fi, fieldnames=fieldnames)
        for rec in reader:
            c5,c3 = rec['coord'].split('-')
            if c5.startswith('c'):
                c5 = c5[1:]
                c3,c5 = c5,c3

            rna_start = int(rec['mrna_start'])
            rna_end = int(rec['mrna_end'])
            coord_5 = int(c5)
            coord_3 = int(c3)
            if rna_start < 0:
                coord = int(c3)
            else:
                coord = int(c5)
            mrna_5 = coord + rna_start
            mrna_3 = coord + rna_end

            #mrna_5 = int(c5)
            #mrna_3 = int(c3)
            #if mrna_5 > mrna_3:
            #    mrna_5, mrna_3 = mrna_3, mrna_5
            targets.append(dict(
                    rank=int(rec['rank'].strip('.')),
                    #coord_5=int(c5),
                    #coord_3=int(c3),
                    coord_5=mrna_5,
                    coord_3=mrna_3,
                    energy=float(rec['energy']),
                    z_score=float(rec['z_score']),
                    locus=rec['locus']))
    return pd.DataFrame.from_records(targets)


def get_regions(df, c5='coord_5', c3='coord_3'):
    '''
    Returns list that contains all unique positions between c3 and c5 in df
    This (along with get_utr_overlap) looks like an ugly hack and is probably done more
    efficiently with pybedtools.
    '''
    regions = []
    for ind,rec in df.iterrows():
        start, end = rec[c5], rec[c3]
        if start > end:
            start, end = end, start
        regions.extend(list(np.arange(start, end)))
    return list(set(regions))


def get_utr_overlap(targets, regions):
    '''
    Returns records in df_targets overlapping with regions given in utr
    coord_5 and coord_3 must be first and second columns in df_targets.
    This (along with get_regions) looks like an ugly hack and is probably done more
    efficiently with pybedtools.
    '''
    mask = targets[['coord_3', 'coord_5']].isin(regions).all(axis=1)
    return targets[mask]
    #return df_targets[df_targets[df_targets.columns[0]].isin(utr) | df_targets[df_targets.columns[1]].isin(utr)]


def get_target_overlap(df, regions):
    '''
    Returns records in df overlapping with regions given in regions
    coord_5 and coord_3 must be third and forth column in df
    '''
    #return df[(df[df.columns[2]].isin(regions)) | (df[df.columns[3]].isin(regions))]
    mask = df[['coord_5']].isin(regions) | df[['coord_3']].isin(regions)
    #print mask.describe()
    return df[mask]


# The following is lifted from the official pysam docs
class Counter:
    counts = 1

    def __init__(self, start=1):
        self.counts = start

    def __call__(self, alignment):
        self.counts += 1

def get_counts(df, bamfile, reference, key5='TSS', key3='first_gene_3'):

    def _get_read_count(rec):
        count = 1
        start = int(rec[key5])
        end = int(rec[key3])
        if end < start:
            start, end = end, start
        for read in bam.fetch(reference, start, end):
            count += 1
        return float(count)

    bam = pysam.AlignmentFile(bamfile, 'rb')
    return df.apply(_get_read_count, axis=1)


def get_coverage(df, bamfile, reference, key5='TSS', key3='first_gene_3'):

    def get_norm_reads(rec):
        c = Counter()
        start = int(rec[key5])
        end = int(rec[key3])
        if end < start:
            start,end = end,start
        bam.fetch(reference, start, end, callback=c)
        if start - end != 0:
            return float(c.counts / abs(start - end))
        else:
            return float(c.counts)

    bam = pysam.Samfile(bamfile, 'rb')
    return df.apply(get_norm_reads, axis=1)

def get_coverage100(df, bamfile, reference):

    def get_norm_reads(rec):
        c = Counter()
        bam.fetch(reference, rec['rna_5'] - 100, rec['rna_3'] + 100, callback=c)
        return float(c.counts / abs((rec['rna_5'] - rec['rna_3'])) + 200)

    bam = pysam.Samfile(bamfile, 'rb')
    return df.apply(get_norm_reads, axis=1)

def get_coverage_df(df, barcodes,
                    res_dir='../results',
                    covfunc=get_coverage,
                    reference='gi|556503834|ref|NC_000913.3|',
                    key5='TSS',
                    key3='first_gene_3'):
    '''
    Iterates over sorted bam files in res_dir directory and computes coverage for
    every barcode given in barcodes.
    '''
    df_ = df.copy()
    d, _, filenames = os.walk(res_dir).next()
    infiles = [f for f in filenames if f.endswith('_sorted.bam')]
    for barcode in barcodes:
        bamfile = os.path.join(d, [f for f in infiles if barcode in f][0])
        df_[barcode] = covfunc(df_, bamfile, reference, key5=key5, key3=key3)
    return df_

def merge_utr5(df_utr5, df_tgt):
    '''
    Merge utr5 and targets dataframes, that is get rna target coords
    and energy into utr5 dataframe.
    '''
    # dfa = df_utr5.copy()
    # dfa['rna_5'] = np.nan
    # dfa['rna_3'] = np.nan
    # dfa['energy'] = np.nan
    # for target in df_tgt.iterrows():
    #     dfa.loc[dfa.coord_5.isin(np.arange(target[1].coord_5, target[1].coord_3)), 'rna_5'] = target[1].coord_5
    #     dfa.loc[dfa.coord_5.isin(np.arange(target[1].coord_5, target[1].coord_3)), 'rna_3'] = target[1].coord_3
    #     dfa.loc[dfa.coord_5.isin(np.arange(target[1].coord_5, target[1].coord_3)), 'energy'] = target[1].energy
    # return dfa.dropna()
    dfa = df_tgt.copy()
    columns = df_utr5.columns
    tgt_columns = df_tgt.columns
    for col in columns:
        if not col in tgt_columns:
            dfa[col] = np.nan
    for ind, target in df_utr5.iterrows():
        for col in columns:
            if not col in tgt_columns:
                c5 = int(target['TSS'])
                c3 = int(target['first_gene_3'])
                if c5 > c3:
                    c5,c3 = c3,c5
                tgt_region = np.arange(c5, c3+1)
                dfa.loc[dfa['coord_5'].isin(tgt_region) | dfa['coord_3'].isin(tgt_region), col] = target[col]
    #print dfa
    return dfa.dropna()

def get_counts_df(barcodes, res_dir='../results'):
    '''
    Aggregates htseq-count results into raw counts dataframe.
    Iterates over files whose name ends with '.counts' in `res_dir` and contains barcodes
    specified in `barcodes`.

    Builds a dataframe containing gene names and counts for the gene for every barcode.
    '''
    df = pd.DataFrame()
    d, _, filenames = os.walk(res_dir).next()
    infiles = [f for f in filenames if f.endswith('.counts')]
    for barcode in barcodes:
        cntfile = os.path.join(d, [f for f in infiles if barcode in f][0])
        df_ = pd.read_csv(cntfile, sep='\t', header=None, names=['gene','counts'])
        if df.empty:
            df['gene'] = df_['gene']
        df[barcode] = df_['counts']
    return df[~df['gene'].str.startswith('__')]

def get_utr_counts_df(df, barcodes, res_dir='../results'):
    '''
    Calculates 5'UTR coverage
    Iterates over files whose name ends with '_sorted.bam' in `res_dir` and contains barcodes
    specified in `barcodes`.

    Adds `utr_<barcode>` column to df DataFrame
    '''
    d, _, filenames = os.walk(res_dir).next()
    infiles = [f for f in filenames if f.endswith('_sorted.bam')]
    for barcode in barcodes:
        bamfile = os.path.join(d, [f for f in infiles if barcode in f][0])
        #df['utr_{0}'.format(barcode)] = get_coverage(df, bamfile, 'gi|556503834|ref|NC_000913.3|',
        #                                             key5='coord_5', key3='coord_3')
        df['utr_{0}'.format(barcode)] = get_counts(df, bamfile, 'gi|556503834|ref|NC_000913.3|',
                                                     key5='coord_5', key3='coord_3')


def get_utr_array(df, barcodes, reference, res_dir='../results'):

    def get_coverage_vector(rec):
        utr = np.zeros(shape=(max_length,), dtype=np.int16)
        start,end = rec['coord_5'], rec['coord_3']
        if start > end:
            start,end = end,start

        pileup = bamfile.pileup(reference, start, end)
        for i,col in enumerate(pileup):
            # I don't know why
            try:
                utr[i] = col.n
            except IndexError:
                pass
            #utr_lengths.append(i)
        return utr

    result = []
    d, _, filenames = os.walk(res_dir).next()
    infiles = [f for f in filenames if f.endswith('_sorted.bam')]
    for barcode in barcodes:
        filename = os.path.join(d, [f for f in infiles if barcode in f][0])
        data = np.ndarray(shape=(num_utrs, max_length), dtype=np.int16)
        bamfile = pysam.AlignmentFile(filename, 'rb')
        #data = df.apply(get_coverage_vector, axis=1)
        #result.append(data1)
        for (i, row) in enumerate(df.iterrows()):
            data[i] = get_coverage_vector(row[1])
        result.append(data)
    return result
